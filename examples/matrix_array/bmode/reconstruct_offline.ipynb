{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc79538a-ac7c-4740-9d91-27230714fae6",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1f5339-d8d2-4f09-973d-717616065344",
   "metadata": {},
   "source": [
    "In the notebook below, we demonstrate how to read matrix-array datasets collected using us4R platform, reconstruct a 3D volume from it, and visualize it. This notebook also serves as an example of how to run ARRUS form offline image reconstruction. \n",
    "\n",
    "We assume here that the user has an NVIDIA CUDA-compatible graphics card and has already installed the required packages (see `requirements.txt`). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592b5a0-5d01-49ff-826a-e05456a75ca4",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"attachment:4da0e64d-81ec-4258-a79b-8f8a8c06bf92.jpg\" alt=\"us4R platform\" width=600/> </td>\n",
    "<td> <img src=\"attachment:eea0f2dc-8bb1-4efe-b0bd-f50c07048415.gif\" alt=\"3D volume\" width=500/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32445d6d-6089-44ee-be85-26181e8a4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pickle\n",
    "import numpy as np\n",
    "from arrus.utils.imaging import *\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2941f493-cbe3-4271-820a-b29017ff7225",
   "metadata": {},
   "source": [
    "# Reading input data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066bff59-c218-4daf-b550-c305b8904f65",
   "metadata": {},
   "source": [
    "The below cell downloads and reads example dataset. Change the `filepath` to load your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aedf794-6ecd-4aeb-a398-fee41c823af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"data.pkl\"\n",
    "if os.path.exists(filename):\n",
    "    print(f\"The file '{filename}' already exists. Skipping download.\")\n",
    "else:\n",
    "    print(f\"Downloading '{filename}'...\")\n",
    "    urllib.request.urlretrieve(\"https://www.dropbox.com/scl/fi/x5w2t5i93w5x10cbsqai3/3d_cyst3_ats560h.pkl?rlkey=hbm1nmppm0vshfjzsbue88jrv&st=ixjedeyk&dl=1\", filename)\n",
    "    print(\"Download complete.\")\n",
    "    \n",
    "filepath = os.path.join(\"./\", filename)\n",
    "with open(filepath, \"rb\") as f:\n",
    "    f = pickle.load(f)\n",
    "f.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97238d4-0715-48cd-bf73-c7819c9b33d4",
   "metadata": {},
   "source": [
    "The dataset includes:\n",
    "- `data`: a sequence of data arrays collected at the consecutive time steps,\n",
    "- `metadata`: metadata that describes the `data`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292c68fb-fae1-41ce-a100-d6258d136703",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = f[\"data\"]\n",
    "metadata = f[\"metadata\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb80c1fd-7158-4c5e-9d02-4583c228cb88",
   "metadata": {},
   "source": [
    "For the datasets we provide, multiple data arrays are collected at each time point, specifically:\n",
    "- 2D B-modes from the planes $x = 0$ and $y = 0$,\n",
    "- raw RF data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f438c57e-6d83-4a56-9f6f-ea9a062f9c44",
   "metadata": {},
   "source": [
    "For each of these data types, relevant metadata is available. For example, we can check the array shapes using the `input_shape` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb14ae60-fce1-4f1e-b6fd-d82b25c2c6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_timestep0 = data[0]\n",
    "print(f\"B-mode OXZ shape: {metadata[0].input_shape}\")\n",
    "print(f\"B-mode OYZ shape: {metadata[1].input_shape}\")\n",
    "print(f\"Raw channel data shape: {metadata[2].input_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2153530-a549-4764-a2c9-b90cd886dda2",
   "metadata": {},
   "source": [
    "In the following sections of the notebook, we will use raw channel data metadata to reconstruct and visualize 3D volume:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9e39e-1c03-48e1-b554-93c6ba1ce6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metadata = f[\"metadata\"][-1]\n",
    "rf_data = np.stack(list(zip(*f[\"data\"]))[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72293bb7-c621-4924-9664-0831ea235ee3",
   "metadata": {},
   "source": [
    "# Volume reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0cb5f-17fb-47cf-9a49-4a32aa8f90cc",
   "metadata": {},
   "source": [
    "The cell below contains the parameters for volume reconstruction. From the notebook's user's perspective, the most important parameters are `x_grid`, `y_grid`, and `z_grid`, which define the $OX$, $OY$, and $OZ$ coordinates of the reconstructed voxels (`y_grid` $\\times$ `x_grid` $\\times$ `z_grid` is reconstructed).\n",
    "\n",
    "The remaining parameters are part of the metadata and should not be modified to ensure correct results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7111259-0b88-4919-94f1-f30d159d378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imaging grid\n",
    "y_grid = np.arange(-8e-3, 8e-3, 0.2e-3)  # [m]\n",
    "x_grid = np.arange(-8e-3, 8e-3, 0.2e-3)  # [m]\n",
    "z_grid = np.arange(0e-3, 40e-3, 0.2e-3)  # [m]\n",
    "\n",
    "# Data specific for the matrix_array example (NOTE: will be included in the metadata model in the future)\n",
    "# a list of TX focus depths, applied in the TX/RX sequence [m]\n",
    "tx_focus = rf_metadata.data_description.custom[\"matrix_array_tx_focus\"]\n",
    "# a list of TX angles (OXZ plane) applied in the TX/RX sequence [rad]\n",
    "tx_ang_zx = rf_metadata.data_description.custom[\"matrix_array_tx_ang_zx\"]\n",
    "# a list of TX angles (OYZ plane) applied in the TX/RX sequence [rad]\n",
    "tx_ang_zy = rf_metadata.data_description.custom[\"matrix_array_tx_ang_zy\"]\n",
    "# The assumed speed of sound.\n",
    "speed_of_sound = rf_metadata.context.medium.speed_of_sound\n",
    "\n",
    "# The TX/RX sequence used for RF data acquisition.\n",
    "sequence = rf_metadata.context.sequence\n",
    "# Sample range: first, last sample.\n",
    "start_sample, end_sample = sequence.ops[0].rx.sample_range\n",
    "n_samples = end_sample - start_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa7920b-6f26-42d5-8bbd-c760233fe4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_focus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462921c4-574d-4de8-830f-25a0edb32607",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_ang_zx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af448c7-d135-4c19-ac6d-63cec5539dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_ang_zy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4e5200-affa-46b2-84ba-7432573d6c7c",
   "metadata": {},
   "source": [
    "The next cell sets up the pipeline for reconstructing a 3D volume from raw channel data.\n",
    "\n",
    "The pipeline consists of a sequence of operations to be performed on the RF data. The input for `step[i]` is the output from `step[i-1]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdbe0a8-6593-41b7-bc2b-f3d20d2cfbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=(\n",
    "        # Reorder data from the physical order (i.e. depending on \n",
    "        # the us4R hardware) to logical order (i.e. (sequence, TX, RX, samples).\n",
    "        #\n",
    "        # Input:\n",
    "        # - array with hardware-specific shape\n",
    "        # - data type: int16\n",
    "        # Output:\n",
    "        # - array with shape (n_seq, n_tx, n_channels, n_samples)\n",
    "        # - data type: int16\n",
    "        RemapToLogicalOrder(),\n",
    "        # Swap the last two axes (-> n_channels, n_samples)\n",
    "        #\n",
    "        # Input:\n",
    "        # - array with shape (n_seq, n_tx, n_samples, n_channels)\n",
    "        # - data type: int16\n",
    "        # Output:\n",
    "        # - array with shape (n_seq, n_tx, n_channels, n_samples)\n",
    "        # - data type: int16\n",
    "        Transpose(axes=(0, 1, 3, 2)),\n",
    "        # Reshape the channels' axis to (n_y, n_x).\n",
    "        # The n_x axis corresponds to the fastest changing dimension\n",
    "        # (i.e. elements that are assigned to the adjacent channels).\n",
    "        #\n",
    "        # Input:\n",
    "        # - array with shape (n_seq, n_tx, n_channels, n_samples)\n",
    "        # - data type: int16\n",
    "        #\n",
    "        # Output:\n",
    "        # - array with shape (n_seq, n_tx, n_y, n_x, n_samples)\n",
    "        # - data type: int16\n",
    "        Reshape(1, len(sequence.ops), 32, 32, n_samples),\n",
    "        # Band-pass (50%-150%) FIR filter.\n",
    "        #\n",
    "        # Input:\n",
    "        # - array with shape (n_seq, n_tx, n_samples, n_channels)\n",
    "        # - data type: int16\n",
    "        # Output:\n",
    "        # - array with shape (n_seq, n_tx, n_channels, n_samples)\n",
    "        # - data type: float32\n",
    "        BandpassFilter(),\n",
    "        # ---  Digital Down Conversion:\n",
    "        #\n",
    "        # - Demodulate for center frequency 3 MHz (based on metadata).\n",
    "        # - low-pass (FIR) filter and decimation\n",
    "        #\n",
    "        # Input:\n",
    "        # - array with shape (n_seq, n_tx, n_y, n_x, n_samples)\n",
    "        # - data type: float32\n",
    "        # Output:\n",
    "        # - array with shape (n_seq, n_tx, n_y, n_x,\n",
    "        #                     n_samples/decimation_factor)\n",
    "        # - data type: complex64\n",
    "        DigitalDownConversion(\n",
    "            decimation_factor=30,\n",
    "            fir_order=64\n",
    "        ),\n",
    "        # Reconstruct low-resolution images.\n",
    "        # The below operation reconstructs directly on the target mesh,\n",
    "        # that is, the output of this stage is a volume, which the\n",
    "        # individual points correspond to the physical position\n",
    "        # in the sonified area (pixels).\n",
    "        # Input:\n",
    "        # - array with shape (n_seq, n_tx, n_y, n_x,\n",
    "        #                     n_samples/decimation_factor)\n",
    "        # - data type: complex64\n",
    "        #\n",
    "        # Output:\n",
    "        # - array with shape (n_seq, n_pix_y, n_pix_x, n_pix_z)\n",
    "        # - data type: complex64\n",
    "        ReconstructLri3D(    \n",
    "            x_grid=x_grid, y_grid=y_grid, z_grid=z_grid,\n",
    "            tx_foc=tx_focus,\n",
    "            tx_ang_zx=tx_ang_zx, \n",
    "            tx_ang_zy=tx_ang_zy,\n",
    "            speed_of_sound=speed_of_sound\n",
    "        ),\n",
    "        # Remove axes with size == 1\n",
    "        # Input:\n",
    "        # - array with shape (n_seq == 1, n_pix_y, n_pix_x, n_pix_z)\n",
    "        # - data type: complex64\n",
    "        # Output:\n",
    "        # - array with shape (n_pix_y, n_pix_x, n_pix_z)\n",
    "        # - data type: complex64\n",
    "        Squeeze(),\n",
    "        # Get the amplitude of the IQ data.\n",
    "        # Input:\n",
    "        # - array with shape (n_pix_y, n_pix_x, n_pix_z)\n",
    "        # - data type: complex64\n",
    "        # Output:\n",
    "        # - array with shape (n_pix_y, n_pix_x, n_pix_z)\n",
    "        # - data type: float32\n",
    "        EnvelopeDetection(),\n",
    "        # Log compress to B-mode image.\n",
    "        #\n",
    "        # Input and Output:\n",
    "        # - array with shape (n_pix_y, n_pix_x, n_pix_z)\n",
    "        # - data type: float32\n",
    "        LogCompression()\n",
    "    ),\n",
    "    placement=\"/GPU:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df87988b-066e-4211-8b80-7d52b0aead62",
   "metadata": {},
   "source": [
    "The pipeline needs to be initialized using the metadata descrbing the input RF data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c401700-12c2-4390-845c-140559ee8a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.prepare(rf_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba571f3f-2e1e-409c-8056-bc7dadca58c5",
   "metadata": {},
   "source": [
    "Next, we can process the data on the GPU using the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eac6a6-1976-4f06-ae49-63f9d497f5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transfer RF data to GPU\n",
    "rf_data_gpu = cp.asarray(rf_data)\n",
    "# Process the data using the pipeline.\n",
    "bmode_gpu = pipeline.process(rf_data_gpu)[0]\n",
    "# Transfer the output B-mode from the GPU to the host RAM memory.\n",
    "bmode = bmode_gpu.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d1ffb-80fe-450d-94f1-b02589ec41cf",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352f83b2-aa86-4ce8-8764-c6366573c5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ny, nx, nz = bmode.shape\n",
    "\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2)\n",
    "ax0.set_title(\"OXZ B-mode\")\n",
    "ax0.set_ylabel(\"OZ (mm)\")\n",
    "ax0.set_xlabel(\"OX (mm)\")\n",
    "ax0.imshow(bmode[ny//2, :, :].T, cmap=\"gray\", vmin=0, vmax=80, extent=np.asarray([np.min(x_grid), np.max(x_grid), np.max(z_grid), np.min(z_grid)])*1e3)\n",
    "\n",
    "ax1.set_title(\"OYZ B-mode\")\n",
    "ax1.set_ylabel(\"OZ (mm)\")\n",
    "ax1.set_xlabel(\"OY (mm)\")\n",
    "ax1.imshow(bmode[:, nx//2, :].T, cmap=\"gray\", vmin=0, vmax=80, extent=np.asarray([np.min(y_grid), np.max(y_grid), np.max(z_grid), np.min(z_grid)])*1e3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ede9a4-7649-4646-bbf6-da0f5ce6082f",
   "metadata": {},
   "source": [
    "# Visualization 3D (interactive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d281a5bc-a10e-4531-8b29-d18c46658963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vtk\n",
    "import panel as pn\n",
    "pn.extension('vtk')\n",
    "\n",
    "\n",
    "camera = {\n",
    "    \"position\": [0, -500, 0], \n",
    "    \"focalPoint\": [50, 50, 100], \n",
    "    \"viewUp\": [0, 0, -1], \n",
    "    \"viewAngle\": 30, \n",
    "}\n",
    "\n",
    "vol = bmode.copy()\n",
    "# removing voxels with low amplitude\n",
    "vol[vol < 20] = np.nan\n",
    "\n",
    "# rendering\n",
    "volume = pn.pane.VTKVolume(\n",
    "    vol, \n",
    "    camera=camera,\n",
    "    origin=(0,0,0),\n",
    "    width=300, \n",
    "    height=300, \n",
    "    spacing=(1,1,1), \n",
    "    interpolation='nearest', \n",
    "    edge_gradient=0.5,\n",
    "    sampling=0.5,\n",
    "    orientation_widget=False,\n",
    "    colormap=\"erdc_rainbow_dark\",\n",
    "    display_volume=True,\n",
    "    display_slices=False,\n",
    "    shadow=True,\n",
    "    ambient=0.5,\n",
    "    diffuse=1,\n",
    "    specular=1,\n",
    "    specular_power=8,\n",
    "    render_background='#808080'\n",
    ")\n",
    "pn.Row(volume.controls(jslink=True), volume)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
